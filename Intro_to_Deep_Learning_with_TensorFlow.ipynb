{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5G_-fW_E6Yn"
      },
      "source": [
        "Hey! Welcome to this short overview and introduction to Deep Learning. The whole entire goal of this little notebook is just to give you an introduction into the main steps of the process of learning, so don't worry about any of the specific details. You especially don't have to worry about the code or what it means. Don't worry about reading the code, it's mainly just there so that you can run it and play around with it if you would like."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fqvSIJaPQd4"
      },
      "source": [
        "The main things that you should really pull away from this is the pipeline, and that the data that you get, and that you split it up into different sets (training, test, sometimes dev).\n",
        "\n",
        "The general pipeline is just this:\n",
        "\n",
        "1.   Gather and prepare data\n",
        "2.   Build a Model\n",
        "3.   Train that model with your training data\n",
        "4.   Evaluate your model with your testing data\n",
        "5.   Depending on your evaluation, try again or deploy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQe5oemigb_t"
      },
      "source": [
        "# **Installs and Imports**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ai09_MXIJPy"
      },
      "source": [
        "This will import all of the libraries that we will be using below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GY12tzNSgnLE",
        "outputId": "35400cf9-1195-4148-fa24-ef7ace5db77e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.12.0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(tf.version.VERSION)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oix1xu9rg4eG"
      },
      "source": [
        "# **Getting a Dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWd70Easg_jt"
      },
      "source": [
        "For this, we will be using the classic MNIST dataset of handwritten digits. This is a widely used dataset as it is simple, easy to access, and is even already in keras. It is just a collection of about 70,0000 28x28 grayscale images of handwritten digits 0-9.\n",
        "\n",
        "For this data, we don't have to do much preparation on it as it is so simple and well prepared. However, the only thing that we have to do is \"normalize\" it. All this means is to take the values which are currently 0-255 integer pixel values, and convert them into easier to process decimal numbers, which in this case are values between 0-1. This is done by simply dividing by 255. This process makes it easier for the neural network to process the inputs that we give it, to make learning faster and easier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pca8PD-RluS"
      },
      "source": [
        "It will also print one of the images in the training dataset so that you can see what these images look like. You can feel free to change the value of \"index\" to see different images within the dataset.\n",
        "\n",
        "If you want to mess around with the datasets, feel free to adjust the \"dataset_size\" to see what changes it makes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "id": "wA0ZPJfXiJS7",
        "outputId": "b23faa33-6347-44c8-f139-43d49b2b405c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "Label = 2\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "# ---- Editable variables ----\n",
        "use_all = False         # Set to True to use entire dataset, false otherwise\n",
        "dataset_size = 3000     # if not using whole dataset, adjust the size here\n",
        "input_norm_val = 255    # This changes the value that we normalize the input images with\n",
        "                        # 255 is best, but try using 1 to see what happens without it\n",
        "\n",
        "# # # Please don't change any of the information below # # #\n",
        "# Load dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
        "if (use_all):\n",
        "  train_labels = train_labels\n",
        "  test_labels = test_labels\n",
        "else:\n",
        "  train_labels = train_labels[:dataset_size]\n",
        "  test_labels = test_labels[:dataset_size]\n",
        "\n",
        "# Print an example\n",
        "index = 5\n",
        "plt.imshow(train_images[index], cmap='gray')\n",
        "print (\"Label = \" + str(np.squeeze(train_labels[index])))\n",
        "\n",
        "# Normalize the images\n",
        "if (use_all):\n",
        "  train_images = train_images / input_norm_val\n",
        "  test_images = test_images / input_norm_val\n",
        "else:\n",
        "  train_images = train_images[:dataset_size] / input_norm_val\n",
        "  test_images = test_images[:dataset_size] / input_norm_val"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Y_bTwKklUzP"
      },
      "source": [
        "# **Model 1 (Basic Neural Network)**\n",
        "To start off, we will be building a very simple neural network. Don't worry about any of the code, this is only to highlight the major steps in learning.\n",
        "\n",
        "Since we already gathered the dataset above, we don't need to worry about that step.\n",
        "\n",
        "First, we are going to build the model itself."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0Vgb8g-hgRe"
      },
      "source": [
        "After our meeting, it seems, you have a pretty good understanding of all of this stuff already. So I added some extra comments below on things that shouldn't be changed as it will break the model if they are. Other than that, feel free to mess around with it as much as you want to.\n",
        "\n",
        "If you want to add more hidden layers, you can copy the line \"tf.keras.layers.Dense(128, activation='relu'),\" and change the number of units (currently 128), or even the activation function if you would like. The same thing can be done with the dropout layer if you want. Just keep the paramater as a value [0,1]."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bkc1NNTclxlf"
      },
      "outputs": [],
      "source": [
        "# Build the model\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(28, 28)),      # Don't Change - Must be first\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(10)                           # Don't Change - Must be last\n",
        "])\n",
        "\n",
        "# Don't change the below code\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SsBIHGQc07g"
      },
      "source": [
        "The code below will give you an overview of the network that was just built above. It will also show just how many parameters that these networks have, both per layer, as well as the sum for the whole network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D58BZYwecsLY",
        "outputId": "46747693-1ce4-48a0-a081-0931817e617d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 784)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               100480    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 101,770\n",
            "Trainable params: 101,770\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBnWIMAPmR3E"
      },
      "source": [
        "Initially after building the model, it is completely useless and produces essentially random results.\n",
        "\n",
        "Let's see how accurate it is initially"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YqXMw6FYHTpp",
        "outputId": "bb37e1f8-b12f-496f-8827-8a152f445a58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "94/94 [==============================] - 1s 2ms/step - loss: 2.4672 - sparse_categorical_accuracy: 0.0870\n",
            "Test Loss: 2.4671573638916016\n",
            "Test Accuracy: 8.699999749660492%\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(\"Test Loss: \" + str(test_loss))\n",
        "print(\"Test Accuracy: \" + str(test_acc * 100) + \"%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Ge86cp1HUAy"
      },
      "source": [
        "So to fix this and make it useful to us, we can go ahead and train it with the dataset that we setup above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsmoRKQUmWnu",
        "outputId": "8582d337-362a-4222-f917-43d866909f1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.8730 - sparse_categorical_accuracy: 0.7503\n",
            "Epoch 2/10\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3703 - sparse_categorical_accuracy: 0.8960\n",
            "Epoch 3/10\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.2595 - sparse_categorical_accuracy: 0.9280\n",
            "Epoch 4/10\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.2085 - sparse_categorical_accuracy: 0.9423\n",
            "Epoch 5/10\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.1703 - sparse_categorical_accuracy: 0.9580\n",
            "Epoch 6/10\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1351 - sparse_categorical_accuracy: 0.9650\n",
            "Epoch 7/10\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1064 - sparse_categorical_accuracy: 0.9747\n",
            "Epoch 8/10\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1049 - sparse_categorical_accuracy: 0.9717\n",
            "Epoch 9/10\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0796 - sparse_categorical_accuracy: 0.9803\n",
            "Epoch 10/10\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0681 - sparse_categorical_accuracy: 0.9837\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fef02075180>"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Feel free to change the values below\n",
        "num_epochs = 10       # Basically controls the amount of training that happens\n",
        "batch_size = 16       # Feel free to mess with this, it is best if it is a power of 2 though\n",
        "\n",
        "# Train the model - Don't change below code\n",
        "model.fit(\n",
        "    train_images,\n",
        "    train_labels,\n",
        "    epochs=num_epochs,\n",
        "    batch_size=batch_size\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00WQK5F_metz"
      },
      "source": [
        "Now that we have trained the model with our dataset, we can go ahead and test it with our test set to see how we did."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1Gvjbl5mkdG",
        "outputId": "46bc7d05-e31d-4db8-9568-a279ef665e2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "94/94 [==============================] - 1s 5ms/step - loss: 0.3092 - sparse_categorical_accuracy: 0.9043\n",
            "Test Loss: 0.30922266840934753\n",
            "Test Accuracy: 90.43333530426025%\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(\"Test Loss: \" + str(test_loss))\n",
        "print(\"Test Accuracy: \" + str(test_acc * 100) + \"%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlyNYW-sts1d"
      },
      "source": [
        "That's the basics of a simple neural network. While it is really simple, it has a lot of parameters and could have a better accuracy.\n",
        "\n",
        "Note: While we can improve the accuracy some more without using models like CNNs, it would take a much larger network and would take a good amount of time to get trained correctly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5xt0biAduFU"
      },
      "source": [
        "# **Model 2 (Convolutional Neural Network)**\n",
        "\n",
        "Over the summer, we most likely won't be doing a ton of making our own models, if at all. Instead, we will be taking the models that other people have made, and importing them to use them (and then making changes to them).\n",
        "\n",
        "Below is an example of that. Except, we will not be changing the basic architecture of this model as it is already set up for what we would like.\n",
        "\n",
        "Again, please do not worry about any of the code. This is just to provide an example of a CNN and to show that this process isn't too scary as it is only a couple of lines of code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNurufrKd_Vs"
      },
      "source": [
        "This model is a convolutional neural network (CNN), which is a type of neural network that is really good for handling images (as well as speech or audio signal inputs). At this stage, don't worry too much about the inner-workings of a CNN.\n",
        "\n",
        "I have pre-trained a CNN to solve the same dataset as above. It can be accessed with the \"my_model.keras\" file that I have shared with you."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5aJMK3QveVAu",
        "outputId": "8e38cba0-5538-4c1f-e94f-8eb5c05e0ba7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 26, 26, 28)        280       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 13, 13, 28)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 4732)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               605824    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 70)                9030      \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 70)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                710       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 615,844\n",
            "Trainable params: 615,844\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.1007 - accuracy: 0.9730\n",
            "Test Loss: 10.072863847017288\n",
            "Test Accuracy: 97.29999899864197\n"
          ]
        }
      ],
      "source": [
        "# Import the saved model\n",
        "conv_model = tf.keras.models.load_model('my_model.keras')\n",
        "\n",
        "# Print a summary of the network\n",
        "conv_model.summary()\n",
        "\n",
        "# Test the new model\n",
        "test_loss, test_acc = conv_model.evaluate(test_images, test_labels)\n",
        "print(\"Test Loss: \" + str(test_loss * 100))\n",
        "print(\"Test Accuracy: \" + str(test_acc * 100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZTMarJ3fUru"
      },
      "source": [
        "That's it! It is essentially a single line of code to import one of these models.\n",
        "\n",
        "As a side note, I only worked on this model for about 10 minutes, so the accuracy is not nearly what it could be if I had spent a little more time on it. It is not uncommon for people to get 99.9% accuracy for this problem when using a CNN instead of a regular neural network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2NM3viDOQ6w"
      },
      "source": [
        "# **Additional Resources**\n",
        "During our meetings, we discussed some extra resources. Here is where they can be found."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MmqRp-COhBw"
      },
      "source": [
        "3Blue1Brown - Deep Learning Series\n",
        "\n",
        "https://www.youtube.com/watch?v=aircAruvnKk&t=2s\n",
        "\n",
        "This is a really solid series that introduces deep learning and provides really great visuals, but don't feel pressured to watch the whole thing if you end up checking it out. He goes into way more detail than you would need to know."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "D2NM3viDOQ6w"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
